{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['teste.csv', 'treino.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn import metrics\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "#from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# load a saved model\n",
    "from keras.models import load_model\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import os\n",
    "%matplotlib inline\n",
    "print(os.listdir(\"../dados/input\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original_data = pd.read_csv('../dados/input/treino.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = original_data.iloc[:,1:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 29.9 ,  77.25,   0.  , ..., 101.  , 178.  , 215.  ],\n",
       "       [ 29.2 ,  74.25,   1.  , ..., 178.  , 215.  , 263.  ],\n",
       "       [ 31.9 ,  67.5 ,   0.  , ..., 215.  , 263.  , 145.  ],\n",
       "       ...,\n",
       "       [ 24.1 ,  88.25,   1.  , ...,   0.  ,   0.  ,   0.  ],\n",
       "       [ 20.3 ,  78.75,   0.  , ...,   0.  ,   0.  ,   0.  ],\n",
       "       [ 25.2 ,  83.5 ,   0.  , ...,   0.  ,   0.  ,   0.  ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = original_data.iloc[:,19].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 42,  70,  64, 101, 178, 215, 263, 145, 295, 351, 387, 294, 194,\n",
       "       460, 363, 437, 314, 212, 396, 336, 427, 312, 218, 407, 428, 306,\n",
       "       220, 367, 352, 463, 320, 306, 451, 353,  95, 149, 209, 227, 202,\n",
       "       233, 391, 358, 456, 335, 323, 469, 319, 297, 411, 370, 412, 331,\n",
       "       255, 446, 394, 472, 361, 263, 428, 336, 470, 343, 232, 449, 386,\n",
       "       477, 377, 347, 480, 359, 224, 450, 375, 491, 347, 266, 415, 405,\n",
       "       464, 358, 253, 446, 388, 523, 346, 245, 438, 361, 503, 319,  39,\n",
       "        45,  97, 115, 138, 134, 211, 308, 353, 401, 382, 321, 352, 428,\n",
       "       453, 433, 376, 449, 403, 286, 408, 393, 442, 431,  17,  12,  17,\n",
       "        27,  16, 141, 117,  42,  20, 363, 162,  35, 351,  21,  23,  27,\n",
       "        28, 162,  23,  14,  84,  41,   9,  15,  15,  17,  26,  10,  14,\n",
       "        17,  26,  10,  22,  14], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../dados/input/teste.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = test_data.iloc[:,19].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.iloc[:,1:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "standardized_X_train = scaler.transform(X_train)\n",
    "standardized_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(\n",
    "                                        monitor = 'mean_squared_error', \n",
    "                                        mode = 'min',\n",
    "                                        min_delta=1,\n",
    "                                        verbose=0,\n",
    "                                        patience = 500\n",
    ")\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='mean_squared_error', mode='min', verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(\n",
    "            Dense(\n",
    "                    9,\n",
    "                    activation='relu',\n",
    "                    input_dim=standardized_X_train.shape[1]\n",
    "            )\n",
    ")\n",
    "model1.add(\n",
    "            Dense(1)\n",
    ")\n",
    "model1.compile(\n",
    "                loss='mean_squared_error',\n",
    "                optimizer='adam',\n",
    "                metrics=[   'accuracy',\n",
    "                            'mse',\n",
    "                            'mae',\n",
    "                        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pyplot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-703cbb97b455>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0msaved_model1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'validation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pyplot' is not defined"
     ]
    }
   ],
   "source": [
    "model1_history = model1.fit(\n",
    "            standardized_X_train,\n",
    "            Y_train,\n",
    "            batch_size=148,\n",
    "            epochs=5000,\n",
    "            validation_split=0.3,\n",
    "            #validation_data=(standardized_X_test,Y_test),\n",
    "            verbose=0,\n",
    "            callbacks=[model_checkpoint,early_stopping_monitor]\n",
    ")\n",
    "\n",
    "saved_model1 = load_model('best_model.h5')\n",
    "\n",
    "pyplot.plot(model1_history.history['loss'], label='train')\n",
    "pyplot.plot(model1_history.history['val_loss'], label='validation')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(\n",
    "            Dense(\n",
    "                    standardized_X_train.shape[1],\n",
    "                    activation='relu',\n",
    "                    input_dim=standardized_X_train.shape[1]\n",
    "            )\n",
    ")\n",
    "model2.add(\n",
    "            Dense(\n",
    "                    9,\n",
    "                    activation='relu',\n",
    "                    input_dim=standardized_X_train.shape[1]\n",
    "            )\n",
    ")\n",
    "model2.add(\n",
    "            Dense(1)\n",
    ")\n",
    "model2.compile(\n",
    "                loss='mean_squared_error',\n",
    "                optimizer='adam',\n",
    "                metrics=[   'accuracy',\n",
    "                            'mse',\n",
    "                            'mae',\n",
    "                        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_history = model2.fit(\n",
    "            standardized_X_train,\n",
    "            Y_train,\n",
    "            batch_size=148,\n",
    "            epochs=5000,\n",
    "            validation_split=0.3,\n",
    "            #validation_data=(standardized_X_test,Y_test),\n",
    "            verbose=0,\n",
    "            callbacks=[model_checkpoint,early_stopping_monitor]\n",
    ")\n",
    "saved_model2 = load_model('best_model.h5')\n",
    "\n",
    "pyplot.plot(model2_history.history['loss'], label='train')\n",
    "pyplot.plot(model2_history.history['val_loss'], label='validation')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(\n",
    "            Dense(\n",
    "                    standardized_X_train.shape[1],\n",
    "                    activation='relu',\n",
    "                    input_dim=standardized_X_train.shape[1]\n",
    "            )\n",
    ")\n",
    "model3.add(\n",
    "            Dense(\n",
    "                    10,\n",
    "                    activation='relu',\n",
    "                    input_dim=standardized_X_train.shape[1]\n",
    "            )\n",
    ")\n",
    "model3.add(\n",
    "            Dense(\n",
    "                    5,\n",
    "                    activation='relu',\n",
    "                    input_dim=10\n",
    "            )\n",
    ")\n",
    "model3.add(\n",
    "            Dense(1)\n",
    ")\n",
    "model3.compile(\n",
    "                loss='mean_squared_error',\n",
    "                optimizer='adam',\n",
    "                metrics=[   'accuracy',\n",
    "                            'mse',\n",
    "                            'mae',\n",
    "                        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3_history = model3.fit(\n",
    "            standardized_X_train,\n",
    "            Y_train,\n",
    "            batch_size=148,\n",
    "            epochs=5000,\n",
    "            validation_split=0.3,\n",
    "            #validation_data=(standardized_X_test,Y_test),\n",
    "            callbacks=[model_checkpoint,early_stopping_monitor]\n",
    ")\n",
    "\n",
    "saved_model3 = load_model('best_model.h5')\n",
    "\n",
    "pyplot.plot(model3_history.history['loss'], label='train')\n",
    "pyplot.plot(model3_history.history['val_loss'], label='validation')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = saved_model1.predict(standardized_X_test)\n",
    "predictions2 = saved_model2.predict(standardized_X_test)\n",
    "predictions3 = saved_model3.predict(standardized_X_test)\n",
    "\n",
    "# evaluate the model\n",
    "train_acc1 = saved_model1.evaluate(standardized_X_train, Y_train)\n",
    "train_acc2 = saved_model2.evaluate(standardized_X_train, Y_train)\n",
    "train_acc3 = saved_model3.evaluate(standardized_X_train, Y_train)\n",
    "test_acc = saved_model3.evaluate(standardized_X_test, Y_test)\n",
    "\n",
    "print(saved_model1.metrics_names)\n",
    "print('Model 1: ') \n",
    "print(train_acc1)\n",
    "print('Model 2: ') \n",
    "print(train_acc2)\n",
    "print('Model 3: ') \n",
    "print(train_acc3)\n",
    "print('Test: ') \n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "plt.scatter(Y_test[:200],predictions1[:200])\n",
    "plt.xlabel('Y Test')\n",
    "plt.ylabel('Model 1 Predicted Y')\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.scatter(Y_test[:200],predictions2[:200])\n",
    "plt.xlabel('Y Test')\n",
    "plt.ylabel('Model 2 Predicted Y')\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.scatter(Y_test[:200],predictions3[:200])\n",
    "plt.xlabel('Y Test')\n",
    "plt.ylabel('Model 3 Predicted Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(predictions1, label='model1')\n",
    "pyplot.bars(Y_test, label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.plot(predictions2, label='model2')\n",
    "pyplot.plot(Y_test, label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.plot(predictions3, label='model3')\n",
    "pyplot.plot(Y_test, label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
