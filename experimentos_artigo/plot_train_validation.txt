
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import LabelEncoder,OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
#from sklearn import metrics

from keras.wrappers.scikit_learn import KerasRegressor
#from keras import metrics
from keras.models import Sequential
from keras.layers import Dense
from keras.callbacks import ModelCheckpoint
from keras.callbacks import EarlyStopping

# load a saved model
from keras.models import load_model

from matplotlib import pyplot

import os
%matplotlib inline
print(os.listdir("../dados/input"))

original_data = pd.read_csv('../dados/input/treino.csv')

X_train = original_data.iloc[:,1:19]

X_train.values

Y_train = original_data.iloc[:,19].values

Y_train

Y_test = test_data.iloc[:,19].values

X_test = test_data.iloc[:,1:19]

scaler = StandardScaler().fit(X_train)
standardized_X_train = scaler.transform(X_train)
standardized_X_test = scaler.transform(X_test)

early_stopping_monitor = EarlyStopping(
                                        monitor = 'mean_squared_error', 
                                        mode = 'min',
                                        min_delta=1,
                                        verbose=0,
                                        patience = 500
)
model_checkpoint = ModelCheckpoint('best_model.h5', monitor='mean_squared_error', mode='min', verbose=0, save_best_only=True)

model1 = Sequential()
model1.add(
            Dense(
                    9,
                    activation='relu',
                    input_dim=standardized_X_train.shape[1]
            )
)
model1.add(
            Dense(1)
)
model1.compile(
                loss='mean_squared_error',
                optimizer='adam',
                metrics=[   'accuracy',
                            'mse',
                            'mae',
                        ]
)

model1_history = model1.fit(
            standardized_X_train,
            Y_train,
            batch_size=148,
            epochs=5000,
            validation_split=0.3,
            #validation_data=(standardized_X_test,Y_test),
            verbose=0,
            callbacks=[model_checkpoint,early_stopping_monitor]
)

saved_model1 = load_model('best_model.h5')

pyplot.plot(model1_history.history['loss'], label='train')
pyplot.plot(model1_history.history['val_loss'], label='validation')
pyplot.legend()
pyplot.show()

